% Template for PLoS
% Version 3.4 January 2017
%
% % % % % % % % % % % % % % % % % % % % % %
%
% -- IMPORTANT NOTE
%
% This template contains comments intended 
% to minimize problems and delays during our production 
% process. Please follow the template instructions
% whenever possible.
%
% % % % % % % % % % % % % % % % % % % % % % % 
%
% Once your paper is accepted for publication, 
% PLEASE REMOVE ALL TRACKED CHANGES in this file 
% and leave only the final text of your manuscript. 
% PLOS recommends the use of latexdiff to track changes during review, as this will help to maintain a clean tex file.
% Visit https://www.ctan.org/pkg/latexdiff?lang=en for info or contact us at latex@plos.org.
%
%
% There are no restrictions on package use within the LaTeX files except that 
% no packages listed in the template may be deleted.
%
% Please do not include colors or graphics in the text.
%
% The manuscript LaTeX source should be contained within a single file (do not use \input, \externaldocument, or similar commands).
%
% % % % % % % % % % % % % % % % % % % % % % %
%
% -- FIGURES AND TABLES
%
% Please include tables/figure captions directly after the paragraph where they are first cited in the text.
%
% DO NOT INCLUDE GRAPHICS IN YOUR MANUSCRIPT
% - Figures should be uploaded separately from your manuscript file. 
% - Figures generated using LaTeX should be extracted and removed from the PDF before submission. 
% - Figures containing multiple panels/subfigures must be combined into one image file before submission.
% For figure citations, please use "Fig" instead of "Figure".
% See http://journals.plos.org/plosone/s/figures for PLOS figure guidelines.
%
% Tables should be cell-based and may not contain:
% - spacing/line breaks within cells to alter layout or alignment
% - do not nest tabular environments (no tabular environments within tabular environments)
% - no graphics or colored text (cell background color/shading OK)
% See http://journals.plos.org/plosone/s/tables for table guidelines.
%
% For tables that exceed the width of the text column, use the adjustwidth environment as illustrated in the example table in text below.
%
% % % % % % % % % % % % % % % % % % % % % % % %
%
% -- EQUATIONS, MATH SYMBOLS, SUBSCRIPTS, AND SUPERSCRIPTS
%
% IMPORTANT
% Below are a few tips to help format your equations and other special characters according to our specifications. For more tips to help reduce the possibility of formatting errors during conversion, please see our LaTeX guidelines at http://journals.plos.org/plosone/s/latex
%
% For inline equations, please be sure to include all portions of an equation in the math environment.  For example, x$^2$ is incorrect; this should be formatted as $x^2$ (or $\mathrm{x}^2$ if the romanized font is desired).
%
% Do not include text that is not math in the math environment. For example, CO2 should be written as CO\textsubscript{2} instead of CO$_2$.
%
% Please add line breaks to long display equations when possible in order to fit size of the column. 
%
% For inline equations, please do not include punctuation (commas, etc) within the math environment unless this is part of the equation.
%
% When adding superscript or subscripts outside of brackets/braces, please group using {}.  For example, change "[U(D,E,\gamma)]^2" to "{[U(D,E,\gamma)]}^2". 
%
% Do not use \cal for caligraphic font.  Instead, use \mathcal{}
%
% % % % % % % % % % % % % % % % % % % % % % % % 
%
% Please contact latex@plos.org with any questions.
%
% % % % % % % % % % % % % % % % % % % % % % % %

\documentclass[10pt,letterpaper]{article}
\usepackage[top=0.85in,left=2.75in,footskip=0.75in]{geometry}

% amsmath and amssymb packages, useful for mathematical formulas and symbols
\usepackage{amsmath,amssymb}

% Use adjustwidth environment to exceed column width (see example table in text)
\usepackage{changepage}

% Use Unicode characters when possible
\usepackage[utf8x]{inputenc}

% textcomp package and marvosym package for additional characters
\usepackage{textcomp,marvosym}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

% Use nameref to cite supporting information files (see Supporting Information section for more info)
\usepackage{nameref,hyperref}

% line numbers
\usepackage[right]{lineno}

% ligatures disabled
\usepackage{microtype}
\DisableLigatures[f]{encoding = *, family = * }

% color can be used to apply background shading to table cells only
\usepackage[table]{xcolor}

% array package and thick rules for tables
\usepackage{array}

% create "+" rule type for thick vertical lines
\newcolumntype{+}{!{\vrule width 2pt}}

% create \thickcline for thick horizontal lines of variable length
\newlength\savedwidth
\newcommand\thickcline[1]{%
  \noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
  \cline{#1}%
  \noalign{\vskip\arrayrulewidth}%
  \noalign{\global\arrayrulewidth\savedwidth}%
}

% \thickhline command for thick horizontal lines that span the table
\newcommand\thickhline{\noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
\hline
\noalign{\global\arrayrulewidth\savedwidth}}


% Remove comment for double spacing
%\usepackage{setspace} 
%\doublespacing

% Text layout
\raggedright
\setlength{\parindent}{0.5cm}
\textwidth 5.25in 
\textheight 8.75in

% Bold the 'Figure #' in the caption and separate it from the title/caption with a period
% Captions will be left justified
\usepackage[aboveskip=1pt,labelfont=bf,labelsep=period,justification=raggedright,singlelinecheck=off]{caption}
\renewcommand{\figurename}{Fig}

% Use the PLoS provided BiBTeX style
\bibliographystyle{plos2015}

% Remove brackets from numbering in List of References
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother

% Leave date blank
\date{}

% Header and Footer with logo
\usepackage{lastpage,fancyhdr,graphicx}
\usepackage{epstopdf}
\pagestyle{myheadings}
\pagestyle{fancy}
\fancyhf{}
\setlength{\headheight}{27.023pt}
\lhead{\includegraphics[width=2.0in]{PLOS-submission.eps}}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\footrule}{\hrule height 2pt \vspace{2mm}}
\fancyheadoffset[L]{2.25in}
\fancyfootoffset[L]{2.25in}
\lfoot{\sf PLOS}

%% Include all macros below

\newcommand{\lorem}{{\bf LOREM}}
\newcommand{\ipsum}{{\bf IPSUM}}

%% END MACROS SECTION


\begin{document}
\vspace*{0.2in}

% Title must be 250 characters or less.
\begin{flushleft}
{\Large
\textbf\newline{Amquery: a unified searchable database of 16S rRNA amplicon libraries} % Please use "sentence case" for title and headings (capitalize only the first word in a title (or heading), the first word in a subtitle (or subheading), and any proper nouns).
}
\newline
% Insert author names, affiliations and corresponding author email (do not include titles, positions, or degrees).
\\


Nikolay Romashchenko \textsuperscript{1 $\ast$},
Ilia Korvigo \textsuperscript{1, 2},
Evgeny Andronov \textsuperscript{1},

\bigskip
\textbf{1} Laboratory of Microbiological Monitoring and Bioremediation of Soils, All-Russia Research Institute for Agricultural Microbiology, St. Petersburg, Russia
\\
\textbf{2} Laboratory of Functional Genomics, Moscow Institute of Physics and Technology, Moscow, Russia
\\
\bigskip

% Insert additional author notes using the symbols described below. Insert symbol callouts after author names as necessary.
% 
% Remove or comment out the author notes below if they aren't used.
%
% Primary Equal Contribution Note
%\Yinyang These authors contributed equally to this work.

% Additional Equal Contribution Note
% Also use this double-dagger symbol for special authorship notes, such as senior authorship.
%\ddag These authors also contributed equally to this work.

% Current address notes
%\textcurrency Current Address: Dept/Program/Center, Institution Name, City, State, Country % change symbol to "\textcurrency a" if more than one current address note
% \textcurrency b Insert second current address 
% \textcurrency c Insert third current address

% Deceased author note
%\dag Deceased

% Group/Consortium Author Note
%\textpilcrow Membership list can be found in the Acknowledgments section.

% Use the asterisk to denote corresponding authorship and provide email address in note below.
* nikolay.romashchenko@gmail.com

\end{flushleft}
% Please keep the abstract below 300 words
\section*{Abstract}
Rapidly increasing amounts of 16S amplicon libraries require the development of efficient methods for similarity search. 
Here we present Amquery, a new tool for fast indexing and similarity search of 16S rRNA amplicon libraries, based on a technique of k-mer abundance comparison.
Experimental results on huge 16S dataset show that Amquery can significantly outperform clustering-based pipelines, implemented in tools such as QIIME, in the index construction and search tasks. 
Amquery is freely available at https://github.com/nromashchenko/amquery.

\linenumbers

% Use "Eq" instead of "Equation" for equation citations.
\section*{Introduction}
High-throughput sequencing of 16S amplicon libraries has become a very popular and powerful way of assessing the structure of various microbial communities \cite{qin2010human, seedorf2014bacteria, ligi2014characterization}.
As the number of published 16S amplicon libraries keeps growing so does the demand for a way to quickly process samples to find related communities similarly to the way BLAST for sequences. Nowadays a single amplicon library can easily contain many thousands of reads, making clustering-based pipelines, implemented in tools such as QIIME \cite{caporaso2010qiime}, inapplicable to large databases. To address these problems, we developed Amquery.


\section*{Methods}
There are two main ideas behind the implementation of Amquery. The first is the use of empirical distribution of k-mers as representation of each library sample. The second is the use of information-theoretic divergence measure as distance function between these representations. 

\subsection*{k-mer counting}
Given a set of 16S amplicon libraries (samples), Amquery begins by representing each of them as a k-mer histogram of corresponding k-mer counts. To reduce memory consumption, each k-mer value is stored as a proper quarternary number.
More formally, every k-mer of input sequence $s = s_0,\dots,s_{n-1}$ is represented as its \textit{lexicographic rank} $\mathrm{lxr}_k(s)$, which equals to the position of the k-mer in the list of all possible k-mers, sorted lexicographically:

\begin{eqnarray}
\label{eq:schemeP}
    \mathrm{lxr}_k(s) = \sum_{i=0}^{k−1} \mathrm{ord}(s_i) \cdot |{\mathcal{L}}|^{k−i−1}
\end{eqnarray}

Here $\mathrm{ord}(s_i)$ is a value of ordering function at $s_i$ over the alphabet ${\mathcal{L}} = \{A, C, G, T \}$. 

The disadvatage of this approach is the upper limit on the length of k-mer, due to the combinatorial explosion of the number of all possible k-mers. Thus, we assume $k \leq 32$ for x64 machine, which allows for storing a k-mer value in a single machine word.
The advantage of this representation is that $\mathrm{lxr}_k$ is a special case of Karp-Rabin hash fingerprint \cite{karp1987efficient}, so it is possible to evaluate a quarternary representation $\mathrm{lxr}_k(s_{i:i+k-1})$ of k-mer $s_{i:i+k-1}$, using the value $\mathrm{lxr}_k(s_{i−1:i+k-2})$ of the previous k-mer $s_{i−1:i+k-2}$, in constant time:

\begin{eqnarray}
\label{eq:schemeP}
    \mathrm{lxr}_k(s_{i:i+k-1}) = |{\mathcal{L}}| \cdot (\mathrm{lxr}_k(s_{i−1:i+k-2}) − ord(s_{i−1}) \cdot 
									 |{\mathcal{L}}|^{k−1}) + ord(s_{i+k−1})
\end{eqnarray}

A set of all lexicographic ranks of k-mers of input sequences is inserted into a counting hash table. Theoretically, a fully k-mer-abundant sample could make this table to grow rapidly, so it is reasonable to limit the size of k-mer to avoid insane expansion of this hash table. Below we demonstrate an example of memory consumption for real metagenomic data on this stage.

\subsection*{Distance metric}
At the next stage, the counted k-mers from the previous step are normalized. Since k-mer distribution vectors are high-dimensional and sparse, Amquery represents them as sparse arrays, each of which is sorted in natural order of integer numbers. 
In our implementation, a sparse array is a key-value storage in which the keys are the lexicographic ranks of corresponding k-mers, and the values are the empirical frequencies.

Thus, each input sample corresponds to a frequency distribution of k-mers, stored implicitly as numbers in quaternary numeral system. These distributions are compared to each other by square root of \textit{Jensen-Shannon divergence} (RJSD) \cite{lin1991divergence}, which satisfies many statistical properties and fits many cases of high-dimensional spaces in $\mathbb{R^\star}$ as distance metric \cite{fuglede2004jensen, endres2003new}. We make use of advantage of specific form of RJSD, presented in \cite{connor2013evaluation}, to speed up distance evaluation over sparse distributions of k-mer frequencies.


\subsection*{Metric indexing}
Amquery uses vantage-point tree (vp-tree) \cite{yianilos1993data, chavez2001searching} as main data structure to provide efficient metric-based indexing and search, using pairwise distances between input 
samples, described above.
Since vantage-point tree is designed to be independent of the space dimension \cite{yianilos1993data}, this allows us to store high-dimensional sparse vectors for virtually no loss of indexing and 
search performance: it takes $\mathcal{O}(n)$ space and $\mathcal{O}(n \log n)$ time in worst case to be built (for input set of $n$ samples), and search query is argued to be $\mathcal{O}(\log n)$ in time, with some reservations. 
For more detailed analysis of vp-tree performance, see \cite{yianilos1993data}.


\section*{Results}
The implementation of Amquery was compared against our own custom solution of similarity search, based on the classic microbiome analysis QIIME pipeline, in the following fashion.
We computed pairwise weighted Unifrac distances \cite{lozupone2011unifrac} and Bray-Curtis similarities for huge 16S metagenomic dataset, and compared the results of similarity search, obtained by Amquery for the same dataset, with weighted Unifrac and Bray-Curtis based similarity search, in terms of speed and time efficiency, and overall search relevance. All of the experiments were run on a machine equipped with an Intel Xeon CPU E5-2650 v3 (2.30 GHz) and a 
Seagate Constellation ES.3 ST3000NM0033 hard drive.

\subsection*{16S rRNA gene metagenomic data}
We analyzed a human gut 16S metagenomic dataset, which consist of 1978 samples, obtained from the Sequence Read Archive \cite{leinonen2010sequence}. 
For each sample, the reads was filtered by length with 250+bp threshold, and rarefied by choosing 1000 sequences per sample randomly.
Resulting samples are split into two parts: referred below to as \textit{main}, the size of which varies in range (100, 200, $\dots$, 1000), and referred below to as \textit{additional}, consist of all the rest samples, accordingly. 


\subsection*{Dataset processing using Amquery}
For every split of the dataset, Amquery index is built for the main part, using $k=15$ as k-mer size. 100 random samples from the main part are searched in resulting index. 
Then a random subset of additional of size 100, 200, $\dots$, 1000 are added to the index separetely. At every stage of processing, peak RAM usage and computational time are measured.


\subsection*{Beta-diversity analysis using QIIME}
\subsubsection*{Reference-based OTU picking}
\subsubsection*{\textit{De novo} OTU picking}


\subsection*{Speed and memory efficiency}
Elapsed time measurements at each stage of processing for reference-based QIIME pipeline (for weighted Unifrac and Bray-Curtis similarities) and Amquery are presented in Table~\ref{table1}. 
The rows present measurements, made for each of the dataset splits, the columns present elapsed time at each stage of pipelines. 
Peak RAM usage for both of pipelines presented in Table~\ref{table2}.

\begin{table}[!ht]
\begin{adjustwidth}{-2.25in}{0in} % Comment out/remove adjustwidth environment if table fits in text column.
\centering
\caption{{\bf Measurements of processing time (m:ss.ms) of Amquery and QIIME-base pipelines }}
\begin{tabular}{|l+l|l|l|l|l|l|l|l|l|}
\hline
\textit{size} & \multicolumn{3}{|l|}{\bf Amquery} & \multicolumn{6}{|l|}{\bf Reference-based QIIME}\\ \hline
& k-mers & indexing & {\bf Total} & pick\_otus & make\_otu & bdiv (wu) & beta\_div (bc) & {\bf Total (wu)} & {\bf Total (bc)}  \\ \thickhline
100 & 0:43.08 & 0:00.74 & {\bf 0:43.82 } & 0:56.55 & 0:01.33 & 0:01.46 & 0:01.52 & {\bf 0:59.34 } & {\bf 0:59.40 } \\ \hline
200 & 1:25.16 & 0:01.51 & {\bf 1:26.67 } & 1:59.69 & 0:01.41 & 0:02.79 & 0:03.31 & {\bf 2:03.89 } & {\bf 2:04.41 } \\ \hline
300 & 2:10.24 & 0:02.40 & {\bf 2:12.64 } & 2:53.94 & 0:01.59 & 0:05.09 & 0:07.61 & {\bf 3:00.62 } & {\bf 3:03.14 } \\ \hline
400 & 2:44.32 & 0:03.13 & {\bf 2:47.45 } & 3:41.92 & 0:01.40 & 0:08.56 & 0:14.67 & {\bf 3:51.88 } & {\bf 3:57.99 } \\ \hline
500 & 3:37.39 & 0:04.31 & {\bf 3:41.70 } & 5:33.65 & 0:01.77 & 0:14.82 & 0:28.01 & {\bf 5:50.24 } & {\bf 6:03.43 } \\ \hline
600 & 4:17.47 & 0:05.45 & {\bf 4:22.92 } & 6:42.26 & 0:01.98 & 0:21.03 & 0:46.02 & {\bf 7:05.27 } & {\bf 7:30.26 } \\ \hline
700 & 5:08.55 & 0:06.00 & {\bf 5:14.55 } & 7:52.58 & 0:02.15 & 0:28.10 & 1:08.47 & {\bf 8:22.83 } & {\bf 9:03.20 } \\ \hline
800 & 5:38.59 & 0:07.07 & {\bf 5:45.66 } & 9:30.34 & 0:02.25 & 0:39.75 & 1:40.54 & {\bf 10:12.34 } & {\bf 11:13.13 } \\ \hline
900 & 6:33.67 & 0:07.83 & {\bf 6:41.50 } & 10:55.35 & 0:02.47 & 0:50.01 & 2:22.95 & {\bf 11:47.83 } & {\bf 13:20.77 } \\ \hline
1000 & 7:15.78 & 0:09.25 & {\bf 7:25.03 } & 11:54.37 & 0:02.54 & 1:04.56 & 2:58.86 & {\bf 13:01.47 } & {\bf 14:55.77 } \\ \hline
\end{tabular}
\begin{flushleft}
Interpretation of headings: \textit{size} is the number of samples, used for index construction. 
\textit{k-mers} is the time spent on k-mer counting. 
\textit{indexing} is the time spent on vp-tree construction, including calculation of necessary RJSD distance values.
\textit{Total} is the total time of processing by Amquery.
\textit{pick\_otus} is the total time spent by pick\_otus.py script.
\textit{make\_otu} is the total time spent by make\_otu\_table.py script.
\textit{bdiv (wu)} and \textit{bdiv (bc)} are the total time spent by beta\_diversity.py script for weighted Unifrac and Bray-Curtis similarities accordingly.
\textit{Total (wu)} and \textit{Total (bc)} are the total time spent by QIIME pipeline for weighted Unifrac and Bray-Curtis similarities accordingly.
\end{flushleft}
\label{table1}
\end{adjustwidth}
\end{table}




\begin{table}[!ht]
\begin{adjustwidth}{-2.25in}{0in} % Comment out/remove adjustwidth environment if table fits in text column.
\centering
\caption{{\bf Peak RAM usage of Amquery and QIIME-base pipelines }}
\begin{tabular}{|l+l|l|l|l|l|l|l|}
\hline
\textit{size} & {\bf Amquery} & \multicolumn{6}{|l|}{\bf Reference-based QIIME}\\ \hline
& {\bf Peak} & pick\_otus & make\_otu & bdiv (wu) & beta\_div (bc) & {\bf Peak (wu)} & {\bf Peak (bc)}  \\ \thickhline
100 & 100Mb & 242Mb & 120Mb & 145Mb & 135Mb & 242Mb & 242Mb \\ \hline
200 & 149Mb & 344Mb & 130Mb & 209Mb & 197Mb & 344Mb & 344Mb \\ \hline
300 & 222Mb & 437Mb & 135Mb & 295Mb & 275Mb & 437Mb & 437Mb \\ \hline
400 & 229Mb & 499Mb & 139Mb & 387Mb & 366Mb & 499Mb & 499Mb \\ \hline
500 & 290Mb & 649Mb & 146Mb & 541Mb & 516Mb & 649Mb & 649Mb \\ \hline
600 & 334Mb & 759Mb & 153Mb & 716Mb & 686Mb & 759Mb & 759Mb \\ \hline
700 & 379Mb & 833Mb & 163Mb & 881Mb & 850Mb & 881Mb & 850Mb \\ \hline
800 & 428Mb & 911Mb & 168Mb & 1.0Gb & 1.0Gb & 1.0Gb & 1.0Gb \\ \hline
900 & 474Mb & 995Mb & 175Mb & 1.3Gb & 1.2Gb & 1.3Gb & 1.2Gb \\ \hline
1000 & 515Mb & 1.0Gb & 183Mb & 1.4Gb & 1.4Gb & 1.4Gb & 1.4Gb \\ \hline
\end{tabular}
\begin{flushleft}
Interpretation of headings is similar to the Table~\ref{table1}. \textit{Peak} columns present the peak RAM usage of corresponding pipelines.   
\end{flushleft}
\label{table2}
\end{adjustwidth}
\end{table}


\subsection*{Similarity search effectiveness}
To estimate relevance of similarity search, provided by Amquery, mean precision at k (MP@K), mean average precision at k (MAP@K), and normalized cumulative discounted gain at k (NCDG@k) \cite{book, jarvelin2000ir, jarvelin2002cumulated}
are evaluated, with the relevance function, declared as follows. For every search query $q$, all the pairwise distances $dist_{QIIME}(q, x)$, provided by QIIME, from $q$ to every sample $x$ in the index, are normalized. 
Thus, resulting relevance value $R(q, r)$ for search output result $r$ is value $dist_{QIIME}(q, r)$, normalized over all the $dist_{QIIME}(q, x)$. Here we use the notation of $dist_{QIIME}(q, r)$ for weighted Unifrac and Bray-Curtis similarity distances.

All effectiveness metrics are evaluated among all the dataset splits, mentioned above, for search query size $k = {1, 3, 5, 7, 10, 15, 20}$ and 100 random samples from the index. Since precision metrics as MP@k and MAP@k require binary relevance function,
$R(q, r)$ values for these metrics are binarized as follows:

\[ R_b(q, r)  =
  \begin{cases}
    1  & r \text{ in top-} k \text{ nearest samples of } q, \text{ according to } dist_{QIIME}\\
    0  &  otherwise \\
  \end{cases}
\] 

MP@k, MAP@k, NDCG@k evaluation results presented in Fig~\ref{fig1}, Fig~\ref{fig2} and Fig~\ref{fig3} respectively.

\begin{figure}[!h]
\caption{{\bf Mean precision at k for Amquery search queries and random sampling from the index as baseline.}
A: According to weighted Unifrac based relevance function. B: According to Bray-Curtis similarity based relevance function.}
\label{fig1}
\end{figure}

\begin{figure}[!h]
\caption{{\bf Mean average precision at k for Amquery search queries and random sampling from the index as baseline.}
A: According to weighted Unifrac based relevance function. B: According to Bray-Curtis similarity based relevance function.}
\label{fig2}
\end{figure}

\begin{figure}[!h]
\caption{{\bf Normalized cumulative discounted gain at k for Amquery search queries and random sampling from the index as baseline.}
A: According to weighted Unifrac based relevance function. B: According to Bray-Curtis similarity based relevance function.}
\label{fig3}
\end{figure}


\subsection*{Conclusions}
We presented a k-mer based approach for fast indexing and searching of 16S amplicon libraries, which designed to outperform clustering-based solutions for similarity search, in terms of speed and memory consumption.
This approach allows for indexing thousands of samples in minutes, and lightning fast similarity search. We demonstrated that similarity search results, based on RJSD distance over estimated k-mer distributions, correspond to a certain extent to the weighted Unifrac based and Bray-Curtis similarity based search results.


\begin{thebibliography}{10}

\bibitem{caporaso2010qiime}
J~Gregory Caporaso, Justin Kuczynski, Jesse Stombaugh, Kyle Bittinger,
  Frederic~D Bushman, Elizabeth~K Costello, Noah Fierer, Antonio~Gonzalez
  Pe{\~n}a, Julia~K Goodrich, Jeffrey~I Gordon, et~al.
\newblock Qiime allows analysis of high-throughput community sequencing data.
\newblock {\em Nature methods}, 7(5):335--336, 2010.

\bibitem{chavez2001searching}
Edgar Ch{\'a}vez, Gonzalo Navarro, Ricardo Baeza-Yates, and Jos{\'e}~Luis
  Marroqu{\'\i}n.
\newblock Searching in metric spaces.
\newblock {\em ACM computing surveys (CSUR)}, 33(3):273--321, 2001.

\bibitem{book}
Prabhakar~Raghavan Christopher D~Manning and Hinrich Schütze.
\newblock {\em Introduction to Information Retrieval}.
\newblock Cambridge University Press, 2008.

\bibitem{connor2013evaluation}
Richard Connor, Franco~Alberto Cardillo, Robert Moss, and Fausto Rabitti.
\newblock Evaluation of jensen-shannon distance over sparse data.
\newblock In {\em International Conference on Similarity Search and
  Applications}, pages 163--168. Springer, 2013.

\bibitem{endres2003new}
Dominik~Maria Endres and Johannes~E Schindelin.
\newblock A new metric for probability distributions.
\newblock {\em IEEE Transactions on Information theory}, 49(7):1858--1860,
  2003.

\bibitem{fuglede2004jensen}
Bent Fuglede and Flemming Topsoe.
\newblock Jensen-shannon divergence and hilbert space embedding.
\newblock In {\em Information Theory, 2004. ISIT 2004. Proceedings.
  International Symposium on}, page~31. IEEE, 2004.

\bibitem{jarvelin2000ir}
Kalervo J{\"a}rvelin and Jaana Kek{\"a}l{\"a}inen.
\newblock Ir evaluation methods for retrieving highly relevant documents.
\newblock In {\em Proceedings of the 23rd annual international ACM SIGIR
  conference on Research and development in information retrieval}, pages
  41--48. ACM, 2000.

\bibitem{jarvelin2002cumulated}
Kalervo J{\"a}rvelin and Jaana Kek{\"a}l{\"a}inen.
\newblock Cumulated gain-based evaluation of ir techniques.
\newblock {\em ACM Transactions on Information Systems (TOIS)}, 20(4):422--446,
  2002.

\bibitem{karp1987efficient}
Richard~M Karp and Michael~O Rabin.
\newblock Efficient randomized pattern-matching algorithms.
\newblock {\em IBM Journal of Research and Development}, 31(2):249--260, 1987.

\bibitem{leinonen2010sequence}
Rasko Leinonen, Hideaki Sugawara, and Martin Shumway.
\newblock The sequence read archive.
\newblock {\em Nucleic acids research}, page gkq1019, 2010.

\bibitem{ligi2014characterization}
Teele Ligi, Kristjan Oopkaup, Marika Truu, Jens-Konrad Preem, Hiie N{\~o}lvak,
  William~J Mitsch, {\"U}lo Mander, and Jaak Truu.
\newblock Characterization of bacterial communities in soil and sediment of a
  created riverine wetland complex using high-throughput 16s rrna amplicon
  sequencing.
\newblock {\em Ecological Engineering}, 72:56--66, 2014.

\bibitem{lin1991divergence}
Jianhua Lin.
\newblock Divergence measures based on the shannon entropy.
\newblock {\em IEEE Transactions on Information theory}, 37(1):145--151, 1991.

\bibitem{lozupone2011unifrac}
Catherine Lozupone, Manuel~E Lladser, Dan Knights, Jesse Stombaugh, and Rob
  Knight.
\newblock Unifrac: an effective distance metric for microbial community
  comparison.
\newblock {\em The ISME journal}, 5(2):169, 2011.

\bibitem{qin2010human}
Junjie Qin, Ruiqiang Li, Jeroen Raes, Manimozhiyan Arumugam,
  Kristoffer~Solvsten Burgdorf, Chaysavanh Manichanh, Trine Nielsen, Nicolas
  Pons, Florence Levenez, Takuji Yamada, et~al.
\newblock A human gut microbial gene catalogue established by metagenomic
  sequencing.
\newblock {\em nature}, 464(7285):59--65, 2010.

\bibitem{seedorf2014bacteria}
Henning Seedorf, Nicholas~W Griffin, Vanessa~K Ridaura, Alejandro Reyes, Jiye
  Cheng, Federico~E Rey, Michelle~I Smith, Gabriel~M Simon, Rudolf~H
  Scheffrahn, Dagmar Woebken, et~al.
\newblock Bacteria from diverse habitats colonize and compete in the mouse gut.
\newblock {\em Cell}, 159(2):253--266, 2014.

\bibitem{yianilos1993data}
Peter~N Yianilos.
\newblock Data structures and algorithms for nearest neighbor search in general
  metric spaces.
\newblock In {\em SODA}, volume~93, pages 311--21, 1993.

\end{thebibliography}



\end{document}

